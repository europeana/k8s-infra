<source>
    @type tail
    @id kubernetes.app.log
    tag kubernetes.app.*
    @label @app

    ## path /var/log/containers/*.log
    path ./dummy_logs/*.log
    # Exclude all system containers. This pattern also matches the NGINX Ingress. We'll handle that separately
    # Keeping this exclusion list up-to-date isn't strictly necessary, as we'll also check if the fluentd/include
    # annotation is set for an application or not.
    exclude_path ["/var/log/containers/fluentd*.log",                     # don't include fluentd pods themselves
                  "/var/log/containers/*_kube-system_*.log",              # exclude all pods in kube_system namespace
                  "/var/log/containers/*_ibm-system_*.log",               # all pods in ibm_system namespace
                  "/var/log/containers/*_cattle-*system_*.log",           # all pods in various cattle related namespaces
                  "/var/log/containers/*_cert-manager_*.log",
                  "/var/log/containers/*_external-secrets_*.log",

                  "/var/log/containers/*_dev_*",                          # all pods in dev namespace (from SX team)
                  "/var/log/containers/portal-js*",                       # all other SX team deployments
                  "/var/log/containers/contribute-*",
                  "/var/log/containers/contentful-proxy-*",
                  "/var/log/containers/media-proxy-js-*",
                  "/var/log/containers/styleguide-*",
                  "/var/log/www-*",
                  "/var/log/containers/cm-acme-http-solver-*",

                  "/var/log/containers/bad-deployment-*",                 # pod eviction stuff created by infra team
                  "/var/log/containers/pod-manager-cronjob-*" ]
    ##pos_file /var/log/kubernetes.app.log.pos
    pos_file ./result/kubernetes.app.log.pos
    read_from_head true

    # We first do some basic parsing of only time and stream, so we can then try and combine multiline logs (e.g. stacktraces)
    <parse>
        # Plugin documentation: https://github.com/repeatedly/fluent-plugin-multi-format-parser#configuration
        # Matches from top to bottom, so more-specific patterns should always come first
        @type multi_format
        # Basic application format
        <pattern>
            format regexp
            expression /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
        </pattern>
        # Fallback: write everything in log field -> goes to unparsable index
        <pattern>
            format regexp
            expression /^(?<log>.*)$/
        </pattern>
        time_format  %Y-%m-%dT%H:%M:%S.%NZ
        time_key time
        time_type string
        localtime false
    </parse>
</source>

<label @app>
    # Include additional kubernetes metadata in log output. These are added to a "kubernetes" property within the log event
    <filter kubernetes.app.**>
        @type kubernetes_metadata
        # Only include pod annotations starting with "fluentd/", ie. fluentd/include and fluentd/multiline
        annotation_match ["^fluentd/*"]
        @id filter_kube_metadata
        # Update Kubernetes metadata every 5 mins, instead of watching for changes
        watch false
        cache_ttl 300
    </filter>

    # Sets three properties on the log event:
    # fluentd_include: value of kubernetes.annotations.fluentd/include, false otherwise
    # fluentd_multiline: value of kubernetes.annotations.fluentd/multiline, false otherwise
    # fluentd_type: app â€“ used to determine the index while writing to ES
    <filter kubernetes.app.**>
        @type record_transformer
        @id id_kubernetes_metadata.fluentd.annotations
        enable_ruby true
        <record>
            fluentd_include  true ## ${record.dig("kubernetes", "annotations", "fluentd/include") ? record.dig("kubernetes", "annotations", "fluentd/include") : ("false")}
            fluentd_multiline true  ## ${record.dig("kubernetes", "annotations", "fluentd/multiline") ? record.dig("kubernetes", "annotations", "fluentd/multiline") : ("false")}
            fluentd_type app
            europeana_cluster "#{ENV['EANA_K8S_CLUSTER']}"
        </record>
    </filter>

    # Discard events without fluentd_include set to "true"
    <filter kubernetes.app.**>
        @type grep
        @id id_grep.fluentd_include
        <regexp>
            key fluentd_include
            pattern /^true$/
        </regexp>
    </filter>

    # Re-tag log event for routing
    <match kubernetes.app.**>
        @type rewrite_tag_filter
        @id kubernetes_app_routing

        # Empty stream field means it's unparsed data, so retag as "unparsable.*"
        <rule>
            key stream
            pattern /^.+$/
            invert true
            tag unparsable.${tag}
        </rule>
        # Re-tag events with fluentd_multiline: false as "plain.*"
        <rule>
            key fluentd_multiline
            pattern /^false$/
            tag plain.${tag}
        </rule>
        # Re-tag events with fluentd_multiline: true as "multiline.*"
        <rule>
            key fluentd_multiline
            pattern /^false$/
            invert true
            tag multiline.${tag}
        </rule>
    </match>

    # Send unparsable items to different index
    <filter unparsable.**>
        @type record_transformer
        @id id_add_unparsable_type
        <record>
            fluentd_type unparsable
        </record>
    </filter>

    # Futher routing....
    #   unparsable.* goes straight to @output
    <match unparsable.**>
        @type relabel
        @label @output
    </match>
    #   plain.* events are processed further
    <match plain.**>
        @type relabel
        @label @app_more_parsing
    </match>
    #   multiline.* events are first combined and then processed further
    <match multiline.**>
        @type relabel
        @label @multiline
    </match>
</label>

# Combine multiline events
<label @multiline>
    <filter multiline.**>
        @log_level trace
        @type concat
        @id id_concat.multiline
        stream_identity_key docker.container_id
        key log   # field that should be merged
        # The "log" part that we parsed always starts with a timestamp, at least at the start of a stacktrace
        # All subsequent lines in a stacktrace, do not have a timestamp, so they are combined
        # Regex matches "2023-02-23T13:20:52.284+01:00" and "13:21:45.159"
        multiline_start_regexp /[^T]?\d{2}:\d{2}:\d{2}\.\d+[^ ]/
        separator " "
        flush_interval 3s
        # timeout label is needed to continue normal operations after flush timeout (see also https://arnoldgalovics.com/java-multiline-logs-fluentd/)
        timeout_label @output
        use_first_timestamp true
    </filter>

    <match multiline.**>
        @type relabel
        @label @app_more_parsing
    </match>
</label>

<label @app_more_parsing>
#     <filter **>
#         @log_level trace
#         @type parser
#         key_name log
#         emit_invalid_record_to_error true
#         <parse>
#             @type multi_format
#             # Regular application format
#             <pattern>
#                 format regexp
#                 expression /(?<time>.+) (?<level>[^ ]*) (?<class>[^:]*):(?<code_line_number >[^ ]*) \[(?<thread>[^ ]*)\] - (?<message>.*)$/
#             </pattern>
#             # Fallback (write everything in log field)
#             <pattern>
#                 format regexp
#                 expression /^(?<log>.*)/
#             </pattern>
#         </parse>
#     </filter>

    <match **>
        @type relabel
        @label @output
    </match>
</label>
